{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST_Deep_Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORT4aJiBk94l9nekHr8JDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qorird/UAS-AI/blob/main/Fashion_MNIST_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "jC-eaf75gjxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1244edcd-deba-4346-a217-39d4c8ca993f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount GDrive : Untuk menyimpan hasil maupun mengambil file dari GDrive untuk diolah\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kita buat beberapa folder yang akan kita gunakan untuk menampung hasil dari pemrosesan nanti\n",
        "# importing os module \n",
        "import os\n",
        "\n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)\"\n",
        "\n",
        "# 01 - Membuat folder dengan nama 'Dataset Original' ---> Untuk menampung dataset kita\n",
        "directory_dataset_original = \"Dataset Original\"\n",
        "\n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory_dataset_original)\n",
        "\n",
        "# Create the directory\n",
        "\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "    print(\"Directory \" + directory_dataset_original + \" created\")\n",
        "except OSError as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRdThl9chH4Z",
        "outputId": "c0058193-0d03-47d5-aaa6-3a2965b33b04"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)/Dataset Original'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 02 - Membuat folder dengan nama 'Analyze Dataset' ---> Untuk menampung hasil proses splitting dan cek dataset\n",
        "directory_analyze_dataset = \"Analyze Dataset\"\n",
        "\n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory_analyze_dataset)\n",
        "\n",
        "# Create the directory\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "    print(\"Directory \" + directory_analyze_dataset + \" created\")\n",
        "except OSError as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEMSkSkOhxfF",
        "outputId": "c536d212-18c0-489c-dc8d-bbba7245ee71"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)/Analyze Dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 03 - Membuat folder dengan nama 'Model Dataset' ---> Pada tahap ini kita telah memg-compile model kita dan menyimpannya di folder ini\n",
        "directory_model_dataset = \"Model Dataset\"\n",
        "\n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory_model_dataset)\n",
        "\n",
        "# Create the directory\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "    print(\"Directory \" + directory_model_dataset + \" created\")\n",
        "except OSError as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlbTc5QBiOi9",
        "outputId": "6047e588-72dc-4232-9d68-f60ede4b189a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)/Model Dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 04 - Membuat folder dengan nama 'Test Algorithm' ---> Voila!, test your dataset and save them here \n",
        "directory_test_algorithm = \"Test Algorithm\"\n",
        "\n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory_test_algorithm)\n",
        "\n",
        "# Create the directory\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "    print(\"Directory \" + directory_test_algorithm + \" created\")\n",
        "except OSError as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs_J9QR9iTwO",
        "outputId": "e6e938c3-27a7-4661-9a76-7b41a37237bc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)/Test Algorithm'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/gdrive/MyDrive/Colab Notebooks/Fashion/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDtoKT0U0KpO",
        "outputId": "dc8be1bb-27b3-43ba-b3c6-d84418963148"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/Fashion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip file dan hapus zip file\n",
        "!unzip \\*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tozptuOJ0cCN",
        "outputId": "b625494e-3acb-472c-e404-4ea74e0b20ee"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive.zip\n",
            "  inflating: fashion-mnist_test.csv  \n",
            "  inflating: fashion-mnist_train.csv  \n",
            "replace t10k-images-idx3-ubyte? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: t10k-images-idx3-ubyte  \n",
            "  inflating: t10k-labels-idx1-ubyte  \n",
            "  inflating: train-images-idx3-ubyte  \n",
            "  inflating: train-labels-idx1-ubyte  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memindah folder train dan val ke Analyze Dataset\n",
        "# Dataset train\n",
        "!mv \"/content/gdrive/MyDrive/Colab Notebooks/Fashion/fashion-mnist_test.csv\" \"/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)/Analyze Dataset\" \n",
        "\n",
        "# Dataset val\n",
        "!mv \"/content/gdrive/MyDrive/Colab Notebooks/Fashion/fashion-mnist_train.csv\" \"/content/gdrive/MyDrive/Colab Notebooks/Deep Learning (Fashion MNIST)/Analyze Dataset\" "
      ],
      "metadata": {
        "id": "gvUT0hnn1JOA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "train_x = train_x.astype('float32') / 255.\n",
        "test_x = test_x.astype('float32') / 255.\n",
        "\n",
        "train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n",
        "test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n",
        "\n",
        "train_y = to_categorical( train_y )\n",
        "test_y = to_categorical( test_y )"
      ],
      "metadata": {
        "id": "72f5S4V_3DCv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction Layer\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv_layer = ZeroPadding2D(padding=(2,2))(inputs) \n",
        "conv_layer = Conv2D(16, (5, 5), strides=(3,3), activation='relu')(conv_layer) \n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer) \n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer) \n",
        "conv_layer = ZeroPadding2D(padding=(1,1))(conv_layer) \n",
        "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "\n",
        "# Flatten feature map to Vector with 576 element.\n",
        "flatten = Flatten()(conv_layer) \n",
        "\n",
        "# Fully Connected Layer\n",
        "fc_layer = Dense(256, activation='relu')(flatten)\n",
        "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
        "outputs = Dense(10, activation='softmax')(fc_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Adam Optimizer and Cross Entropy Loss\n",
        "adam = Adam(lr=0.0001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print Model Summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl_pHq6c3VZP",
        "outputId": "26d6c2a9-08db-402b-ed0a-f6680025149f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " zero_padding2d_12 (ZeroPadd  (None, 32, 32, 1)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 10, 10, 16)        416       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 3, 3, 32)          4640      \n",
            "                                                                 \n",
            " zero_padding2d_13 (ZeroPadd  (None, 5, 5, 32)         0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 3, 3, 64)          18496     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 256)               147712    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 188,362\n",
            "Trainable params: 188,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TensorBoard\n",
        "callbacks = TensorBoard(log_dir='./Graph')\n",
        "\n",
        "# Train for 100 Epochs and use TensorBoard Callback\n",
        "model.fit(train_x, train_y, batch_size=256, epochs=130, verbose=1, validation_data=(test_x, test_y), callbacks=[callbacks])\n",
        "\n",
        "# Save Weights\n",
        "model.save_weights('weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GXK9NVV3c0Y",
        "outputId": "c45bc33b-a63a-4a89-af7b-d88f22df770d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 1.4041 - accuracy: 0.5789 - val_loss: 0.7869 - val_accuracy: 0.7067\n",
            "Epoch 2/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.7038 - accuracy: 0.7362 - val_loss: 0.6817 - val_accuracy: 0.7500\n",
            "Epoch 3/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.6315 - accuracy: 0.7639 - val_loss: 0.6145 - val_accuracy: 0.7767\n",
            "Epoch 4/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.5919 - accuracy: 0.7819 - val_loss: 0.5855 - val_accuracy: 0.7901\n",
            "Epoch 5/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.5594 - accuracy: 0.7967 - val_loss: 0.5543 - val_accuracy: 0.7991\n",
            "Epoch 6/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.5354 - accuracy: 0.8062 - val_loss: 0.5369 - val_accuracy: 0.8053\n",
            "Epoch 7/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.5161 - accuracy: 0.8136 - val_loss: 0.5357 - val_accuracy: 0.7983\n",
            "Epoch 8/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.5001 - accuracy: 0.8206 - val_loss: 0.5227 - val_accuracy: 0.8109\n",
            "Epoch 9/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.4874 - accuracy: 0.8236 - val_loss: 0.4947 - val_accuracy: 0.8221\n",
            "Epoch 10/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.4755 - accuracy: 0.8287 - val_loss: 0.4834 - val_accuracy: 0.8258\n",
            "Epoch 11/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.4635 - accuracy: 0.8332 - val_loss: 0.4817 - val_accuracy: 0.8301\n",
            "Epoch 12/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.4558 - accuracy: 0.8356 - val_loss: 0.4682 - val_accuracy: 0.8326\n",
            "Epoch 13/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.4456 - accuracy: 0.8402 - val_loss: 0.4620 - val_accuracy: 0.8336\n",
            "Epoch 14/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.4376 - accuracy: 0.8423 - val_loss: 0.4609 - val_accuracy: 0.8358\n",
            "Epoch 15/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.4284 - accuracy: 0.8469 - val_loss: 0.4506 - val_accuracy: 0.8356\n",
            "Epoch 16/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.4212 - accuracy: 0.8493 - val_loss: 0.4410 - val_accuracy: 0.8430\n",
            "Epoch 17/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.4118 - accuracy: 0.8525 - val_loss: 0.4416 - val_accuracy: 0.8413\n",
            "Epoch 18/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.4088 - accuracy: 0.8528 - val_loss: 0.4312 - val_accuracy: 0.8449\n",
            "Epoch 19/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.4008 - accuracy: 0.8561 - val_loss: 0.4172 - val_accuracy: 0.8507\n",
            "Epoch 20/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3933 - accuracy: 0.8590 - val_loss: 0.4262 - val_accuracy: 0.8458\n",
            "Epoch 21/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.3909 - accuracy: 0.8598 - val_loss: 0.4063 - val_accuracy: 0.8535\n",
            "Epoch 22/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3847 - accuracy: 0.8618 - val_loss: 0.4018 - val_accuracy: 0.8534\n",
            "Epoch 23/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3799 - accuracy: 0.8642 - val_loss: 0.4000 - val_accuracy: 0.8547\n",
            "Epoch 24/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3748 - accuracy: 0.8656 - val_loss: 0.4060 - val_accuracy: 0.8549\n",
            "Epoch 25/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.3703 - accuracy: 0.8670 - val_loss: 0.3918 - val_accuracy: 0.8578\n",
            "Epoch 26/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3639 - accuracy: 0.8701 - val_loss: 0.3908 - val_accuracy: 0.8618\n",
            "Epoch 27/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3607 - accuracy: 0.8708 - val_loss: 0.3859 - val_accuracy: 0.8627\n",
            "Epoch 28/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3603 - accuracy: 0.8712 - val_loss: 0.3786 - val_accuracy: 0.8618\n",
            "Epoch 29/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3526 - accuracy: 0.8744 - val_loss: 0.3772 - val_accuracy: 0.8645\n",
            "Epoch 30/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.3503 - accuracy: 0.8748 - val_loss: 0.3814 - val_accuracy: 0.8636\n",
            "Epoch 31/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3482 - accuracy: 0.8755 - val_loss: 0.3815 - val_accuracy: 0.8634\n",
            "Epoch 32/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3435 - accuracy: 0.8771 - val_loss: 0.3704 - val_accuracy: 0.8681\n",
            "Epoch 33/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.3404 - accuracy: 0.8782 - val_loss: 0.3714 - val_accuracy: 0.8640\n",
            "Epoch 34/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3375 - accuracy: 0.8792 - val_loss: 0.3659 - val_accuracy: 0.8644\n",
            "Epoch 35/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3344 - accuracy: 0.8794 - val_loss: 0.3659 - val_accuracy: 0.8680\n",
            "Epoch 36/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3308 - accuracy: 0.8818 - val_loss: 0.3589 - val_accuracy: 0.8711\n",
            "Epoch 37/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.3293 - accuracy: 0.8821 - val_loss: 0.3604 - val_accuracy: 0.8706\n",
            "Epoch 38/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3260 - accuracy: 0.8829 - val_loss: 0.3534 - val_accuracy: 0.8727\n",
            "Epoch 39/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3228 - accuracy: 0.8852 - val_loss: 0.3517 - val_accuracy: 0.8736\n",
            "Epoch 40/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3202 - accuracy: 0.8856 - val_loss: 0.3496 - val_accuracy: 0.8738\n",
            "Epoch 41/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3179 - accuracy: 0.8860 - val_loss: 0.3486 - val_accuracy: 0.8733\n",
            "Epoch 42/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3175 - accuracy: 0.8866 - val_loss: 0.3520 - val_accuracy: 0.8701\n",
            "Epoch 43/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3155 - accuracy: 0.8876 - val_loss: 0.3480 - val_accuracy: 0.8732\n",
            "Epoch 44/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.3132 - accuracy: 0.8880 - val_loss: 0.3457 - val_accuracy: 0.8753\n",
            "Epoch 45/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3102 - accuracy: 0.8880 - val_loss: 0.3397 - val_accuracy: 0.8779\n",
            "Epoch 46/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3085 - accuracy: 0.8905 - val_loss: 0.3465 - val_accuracy: 0.8759\n",
            "Epoch 47/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.3067 - accuracy: 0.8899 - val_loss: 0.3393 - val_accuracy: 0.8767\n",
            "Epoch 48/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3058 - accuracy: 0.8899 - val_loss: 0.3382 - val_accuracy: 0.8788\n",
            "Epoch 49/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.3014 - accuracy: 0.8922 - val_loss: 0.3511 - val_accuracy: 0.8726\n",
            "Epoch 50/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2997 - accuracy: 0.8924 - val_loss: 0.3328 - val_accuracy: 0.8781\n",
            "Epoch 51/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2989 - accuracy: 0.8931 - val_loss: 0.3553 - val_accuracy: 0.8689\n",
            "Epoch 52/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2986 - accuracy: 0.8928 - val_loss: 0.3352 - val_accuracy: 0.8771\n",
            "Epoch 53/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.2948 - accuracy: 0.8946 - val_loss: 0.3354 - val_accuracy: 0.8782\n",
            "Epoch 54/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.2928 - accuracy: 0.8960 - val_loss: 0.3305 - val_accuracy: 0.8824\n",
            "Epoch 55/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.2925 - accuracy: 0.8945 - val_loss: 0.3342 - val_accuracy: 0.8803\n",
            "Epoch 56/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2898 - accuracy: 0.8958 - val_loss: 0.3301 - val_accuracy: 0.8817\n",
            "Epoch 57/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2898 - accuracy: 0.8970 - val_loss: 0.3259 - val_accuracy: 0.8808\n",
            "Epoch 58/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2862 - accuracy: 0.8976 - val_loss: 0.3339 - val_accuracy: 0.8801\n",
            "Epoch 59/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2853 - accuracy: 0.8977 - val_loss: 0.3363 - val_accuracy: 0.8764\n",
            "Epoch 60/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.2825 - accuracy: 0.8982 - val_loss: 0.3284 - val_accuracy: 0.8825\n",
            "Epoch 61/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2807 - accuracy: 0.8995 - val_loss: 0.3257 - val_accuracy: 0.8832\n",
            "Epoch 62/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.2816 - accuracy: 0.8992 - val_loss: 0.3248 - val_accuracy: 0.8826\n",
            "Epoch 63/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2794 - accuracy: 0.8995 - val_loss: 0.3224 - val_accuracy: 0.8838\n",
            "Epoch 64/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2757 - accuracy: 0.9006 - val_loss: 0.3175 - val_accuracy: 0.8863\n",
            "Epoch 65/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2759 - accuracy: 0.8997 - val_loss: 0.3167 - val_accuracy: 0.8874\n",
            "Epoch 66/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2740 - accuracy: 0.9008 - val_loss: 0.3198 - val_accuracy: 0.8856\n",
            "Epoch 67/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2721 - accuracy: 0.9024 - val_loss: 0.3164 - val_accuracy: 0.8859\n",
            "Epoch 68/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2715 - accuracy: 0.9019 - val_loss: 0.3162 - val_accuracy: 0.8883\n",
            "Epoch 69/130\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.2698 - accuracy: 0.9024 - val_loss: 0.3189 - val_accuracy: 0.8850\n",
            "Epoch 70/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2676 - accuracy: 0.9027 - val_loss: 0.3183 - val_accuracy: 0.8857\n",
            "Epoch 71/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2674 - accuracy: 0.9038 - val_loss: 0.3143 - val_accuracy: 0.8845\n",
            "Epoch 72/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2652 - accuracy: 0.9043 - val_loss: 0.3166 - val_accuracy: 0.8858\n",
            "Epoch 73/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2639 - accuracy: 0.9047 - val_loss: 0.3102 - val_accuracy: 0.8886\n",
            "Epoch 74/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2633 - accuracy: 0.9054 - val_loss: 0.3153 - val_accuracy: 0.8865\n",
            "Epoch 75/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2615 - accuracy: 0.9063 - val_loss: 0.3098 - val_accuracy: 0.8874\n",
            "Epoch 76/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2600 - accuracy: 0.9063 - val_loss: 0.3131 - val_accuracy: 0.8873\n",
            "Epoch 77/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2593 - accuracy: 0.9062 - val_loss: 0.3077 - val_accuracy: 0.8909\n",
            "Epoch 78/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2580 - accuracy: 0.9065 - val_loss: 0.3081 - val_accuracy: 0.8899\n",
            "Epoch 79/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2552 - accuracy: 0.9080 - val_loss: 0.3077 - val_accuracy: 0.8906\n",
            "Epoch 80/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2546 - accuracy: 0.9076 - val_loss: 0.3083 - val_accuracy: 0.8905\n",
            "Epoch 81/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2539 - accuracy: 0.9071 - val_loss: 0.3135 - val_accuracy: 0.8866\n",
            "Epoch 82/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2512 - accuracy: 0.9093 - val_loss: 0.3162 - val_accuracy: 0.8860\n",
            "Epoch 83/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2501 - accuracy: 0.9100 - val_loss: 0.3103 - val_accuracy: 0.8883\n",
            "Epoch 84/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2487 - accuracy: 0.9101 - val_loss: 0.3077 - val_accuracy: 0.8898\n",
            "Epoch 85/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2483 - accuracy: 0.9099 - val_loss: 0.3200 - val_accuracy: 0.8856\n",
            "Epoch 86/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2480 - accuracy: 0.9102 - val_loss: 0.3055 - val_accuracy: 0.8893\n",
            "Epoch 87/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2469 - accuracy: 0.9107 - val_loss: 0.3063 - val_accuracy: 0.8902\n",
            "Epoch 88/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2444 - accuracy: 0.9113 - val_loss: 0.3080 - val_accuracy: 0.8925\n",
            "Epoch 89/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2426 - accuracy: 0.9125 - val_loss: 0.3064 - val_accuracy: 0.8888\n",
            "Epoch 90/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2421 - accuracy: 0.9123 - val_loss: 0.3038 - val_accuracy: 0.8908\n",
            "Epoch 91/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2414 - accuracy: 0.9128 - val_loss: 0.3005 - val_accuracy: 0.8925\n",
            "Epoch 92/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2389 - accuracy: 0.9140 - val_loss: 0.3062 - val_accuracy: 0.8915\n",
            "Epoch 93/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2371 - accuracy: 0.9140 - val_loss: 0.3066 - val_accuracy: 0.8893\n",
            "Epoch 94/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2367 - accuracy: 0.9146 - val_loss: 0.3047 - val_accuracy: 0.8894\n",
            "Epoch 95/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2351 - accuracy: 0.9148 - val_loss: 0.3005 - val_accuracy: 0.8912\n",
            "Epoch 96/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2339 - accuracy: 0.9155 - val_loss: 0.2987 - val_accuracy: 0.8927\n",
            "Epoch 97/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2327 - accuracy: 0.9158 - val_loss: 0.3038 - val_accuracy: 0.8887\n",
            "Epoch 98/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2323 - accuracy: 0.9160 - val_loss: 0.2941 - val_accuracy: 0.8951\n",
            "Epoch 99/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2308 - accuracy: 0.9158 - val_loss: 0.3022 - val_accuracy: 0.8911\n",
            "Epoch 100/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2291 - accuracy: 0.9171 - val_loss: 0.2985 - val_accuracy: 0.8908\n",
            "Epoch 101/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2283 - accuracy: 0.9174 - val_loss: 0.3061 - val_accuracy: 0.8891\n",
            "Epoch 102/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2296 - accuracy: 0.9165 - val_loss: 0.2990 - val_accuracy: 0.8940\n",
            "Epoch 103/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2258 - accuracy: 0.9181 - val_loss: 0.2957 - val_accuracy: 0.8949\n",
            "Epoch 104/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2262 - accuracy: 0.9177 - val_loss: 0.2963 - val_accuracy: 0.8926\n",
            "Epoch 105/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2249 - accuracy: 0.9186 - val_loss: 0.2976 - val_accuracy: 0.8947\n",
            "Epoch 106/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2238 - accuracy: 0.9182 - val_loss: 0.3037 - val_accuracy: 0.8904\n",
            "Epoch 107/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2206 - accuracy: 0.9194 - val_loss: 0.2962 - val_accuracy: 0.8924\n",
            "Epoch 108/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2219 - accuracy: 0.9197 - val_loss: 0.2926 - val_accuracy: 0.8953\n",
            "Epoch 109/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2211 - accuracy: 0.9197 - val_loss: 0.2944 - val_accuracy: 0.8951\n",
            "Epoch 110/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2194 - accuracy: 0.9207 - val_loss: 0.2948 - val_accuracy: 0.8940\n",
            "Epoch 111/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2179 - accuracy: 0.9213 - val_loss: 0.2954 - val_accuracy: 0.8961\n",
            "Epoch 112/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2182 - accuracy: 0.9204 - val_loss: 0.2988 - val_accuracy: 0.8933\n",
            "Epoch 113/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2153 - accuracy: 0.9220 - val_loss: 0.2925 - val_accuracy: 0.8957\n",
            "Epoch 114/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2153 - accuracy: 0.9216 - val_loss: 0.2969 - val_accuracy: 0.8965\n",
            "Epoch 115/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2134 - accuracy: 0.9225 - val_loss: 0.2949 - val_accuracy: 0.8941\n",
            "Epoch 116/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2123 - accuracy: 0.9235 - val_loss: 0.2940 - val_accuracy: 0.8967\n",
            "Epoch 117/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2115 - accuracy: 0.9233 - val_loss: 0.3017 - val_accuracy: 0.8930\n",
            "Epoch 118/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2105 - accuracy: 0.9231 - val_loss: 0.2935 - val_accuracy: 0.8957\n",
            "Epoch 119/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2107 - accuracy: 0.9236 - val_loss: 0.2910 - val_accuracy: 0.8970\n",
            "Epoch 120/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2076 - accuracy: 0.9248 - val_loss: 0.2940 - val_accuracy: 0.8962\n",
            "Epoch 121/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2082 - accuracy: 0.9241 - val_loss: 0.2945 - val_accuracy: 0.8945\n",
            "Epoch 122/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2064 - accuracy: 0.9250 - val_loss: 0.2931 - val_accuracy: 0.8957\n",
            "Epoch 123/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2044 - accuracy: 0.9255 - val_loss: 0.3039 - val_accuracy: 0.8927\n",
            "Epoch 124/130\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.2065 - accuracy: 0.9247 - val_loss: 0.2963 - val_accuracy: 0.8958\n",
            "Epoch 125/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2035 - accuracy: 0.9262 - val_loss: 0.2906 - val_accuracy: 0.8969\n",
            "Epoch 126/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2033 - accuracy: 0.9265 - val_loss: 0.2972 - val_accuracy: 0.8951\n",
            "Epoch 127/130\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.2016 - accuracy: 0.9270 - val_loss: 0.2916 - val_accuracy: 0.9003\n",
            "Epoch 128/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.2007 - accuracy: 0.9275 - val_loss: 0.2964 - val_accuracy: 0.8969\n",
            "Epoch 129/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.1995 - accuracy: 0.9271 - val_loss: 0.2919 - val_accuracy: 0.8981\n",
            "Epoch 130/130\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.1994 - accuracy: 0.9278 - val_loss: 0.2935 - val_accuracy: 0.8981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction Layer\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv_layer = ZeroPadding2D(padding=(2,2))(inputs)\n",
        "conv_layer = Conv2D(16, (5, 5), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
        "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
        "\n",
        "# Flatten feature map to Vector with 576 element.\n",
        "flatten = Flatten()(conv_layer)\n",
        "\n",
        "# Fully Connected Layer\n",
        "fc_layer = Dense(256, activation='relu')(flatten)\n",
        "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
        "outputs = Dense(10, activation='softmax')(fc_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "ZctcjFAw7O1q"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T8kkWaI177ph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}